<!DOCTYPE html>
<html lang="en">
<head>
  <title>Data quality</title>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1">
  <link rel="stylesheet" href="../styles/screen-16x10.css">
  <link rel="stylesheet" href="../styles/custom.css">
</head>
<body class="shower list">
  <header class="caption">
    <h1><a class="series" href="../">Linked Data for Librarians</a></h1>
    <p>
      by <a href="http://homepages.ulb.ac.be/~svhoolan/">Seth van Hooland</a>
      and <a href="https://ruben.verborgh.org/">Ruben Verborgh</a>
    </p>
    <h2>Part 1 – Module 4: <em>Data quality</em></h2>
    <ul class="links">
      <li class="prev">Previous module: <a href="../rdf/">Possibilities and limitations of RDF</a></li>
      <li class="next">Next module: <a href="../cleaning/">Data profiling and cleaning</a></li>
    </ul>
  </header>

  <nav>
    <h2>Modules</h2>
    <ul>
      <li><a href="/introduction/">Introduction</a></li>
      <li><a href="/modeling/">Understanding data models</a></li>
      <li><a href="/possibilities/">Possibilities and limitations of RDF</a></li>
      <li class="current"><a href="/quality/">Data quality</a></li>
      <li><a href="/cleaning/">Data profiling and cleaning</a></li>
      <li><a href="/reconciliation/">Vocabulary reconciliation</a></li>
      <li><a href="/enrichment/">Metadata enriching</a></li>
      <li><a href="/rest/">REST</a></li>
      <li><a href="/decentralization/">Decentralization and federation</a></li>
      <li><a href="/conclusions/">Conclusions</a></li>
    </ul>
  </nav>

  <div class="title slide" id="title">
    <h2><a class="series" href="../">Linked Data for Librarians</a></h2>
    <p>
      by <a href="http://homepages.ulb.ac.be/~svhoolan/">Seth van Hooland</a>
      and <a href="https://ruben.verborgh.org/">Ruben Verborgh</a>
    </p>
    <h3>Part 1 – Module 4: <em>Data quality</em></h3>
    <p class="logos">
      <a href="https://www.imls.gov/"><img alt="Institute of Museum and Library Services" src="../images/imls.svg"></a>
      <a href="http://drexel.edu/cci/"><img alt="Drexel University College of Computing &amp; Informatics" src="../images/drexel.png"></a>
    </p>
    <p class="license">
      <a rel="license" href="https://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" src="../images/cc-by.svg" /></a>
      Except where otherwise noted, the content of these slides is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
    </p>
  </div>

  <div class="slide" id="intro">
    <iframe class="cover width height" src="https://www.youtube.com/embed/CPjvdVs3cHA?hl=en&amp;color=white&amp;iv_load_policy=3&amp;disablekb=1&amp;rel=0&amp;showinfo=0&amp;autohide=1"></iframe>
  </div>

<div class="slide" id="party">
    <figure class="cover width">
        <img src="images/party.jpg"
             alt="[The Open-World Assumption can have a dramatic impact.]">
      <figcaption>
        ©2016 <a href="http://www.theherald.com.au/story/1836907/landlord-faces-15000-bill-after-party/">The Examiner</a>
      </figcaption>
    </figure>
    <footer>
      <p>Linked Data have put data quality high on the agenda, especially for librarians.
        Putting the open-world assumption in practice implies you loose control over the
      quality of the data one is drawing in. Consuming and re-using data in a decentralised manner
      undermines a lot of the traditional practices from the library community. For example,
      the practice of copy cataloging always has been based on the assumption of a centralised
      quality control. By design, Linked Data brings together information from various sources.
      It’s like publishing your birthday party as a public-event on social media.
      You don’t know who will show up…</p>
    </footer>
  </div>


  <div class="slide" id="quality">
    <h2>Achilles heel of Linked Data</h2>
  	<ul>
  	<li>As automated reuse of data rises, so does our dependency on their quality</li>
  	<li>Anyone interested in Linked Data should first of all come to terms with
  	the quality of their own and other organisation’s data</li>
    <li>Aggregating data on a massive scale has
    put the topic of data quality high on the agenda</li>
  	</ul>
  </div>

  <div class="slide" id="overview_books">
    <figure class="cover width">
        <img src="images/quality.jpg"
             alt="[Book overview.]">
    </figure>
    <footer>
      <p>A lot of books have been published on the theme of data quality, and professional and academic
      organisations have been launched to tackle the topic. One of the best
      references out there is without a doubt Jack Olson’s book <cite><a href="https://www.amazon.com/Data-Quality-Accuracy-Dimension-Management/dp/1558608915">
      Data quality—The Accuracy Dimension</a></cite>.</p>
    </footer>
  </div>

  <div class="slide" id="blooming_field">
    <h2>Relevant but complex topic</h2>
  	<ul>
  	<li>Blooming but problematic new field</li>
  	<li>Examples:
  	<ul>
  		<li>Interpretation of climate change data: the data which indicated holes in the
        ozone layer were considered at first as errors</li>
  		<li><a href="https://en.wikipedia.org/wiki/Data_Quality_Act">Data Quality Act</a>:
        extremely complex to put in practice,
      as it is complex to define what good quality data are</li>
  	</ul>
  	</li>

  	</ul>
  </div>

 <div class="slide" id="definition">
    <h2>
      How can we define data quality?
    </h2>
    <blockquote class="next">
      <p>The totality of features and characteristics<br>of a product, process or service that bears<br>
      on its ability to statisfy stated or implicit needs.</p>
      <cite><a href="https://www.iso.org/standard/42180.html">ISO, 2005</a></cite>
    </blockquote>
    <p>Commonly referred to in the literature as the “fitness for purpose” definition</p>
  </div>

  <div class="slide" id="empirical_deterministic">
    <h2>Differentiate deterministic and empirical data</h2>
  	<ul>
  	<li>Deterministic data:
  		<ul>
  		<li>Existence of a persistent theory makes it possible to decide whether or not a value is correct</li>
  		<li>Example: in algebra, 1+1 will always be 2</li>
  		</ul>
  	</li>
  	<li>Empirical data:
  		<ul>
  		<li>Absence of a direct frame of reference to validate data, subject to human interpretation and evolution
  		through time</li>
  		<li>Example: medical field—new illnesses constantly appear</li>
  		</ul>
  	</li>
  	</ul>
  </div>

  <div class="slide" id="impact_time">
    <figure class="cover width">
        <img src="images/time.jpg"
             alt="[Impact of time.]">
             <figcaption>
               ©2009 <a href="https://commons.wikimedia.org/wiki/File:Furcifer_pardalis_-Z%C3%BCrich_Zoo-8a.jpg">
                 Marc Staub</a>
             </figcaption>
    </figure>
    <footer>
      <p>A key characteristic of data quality is that we live in
      an empirical world, which continuously changes… Imagine you
    have to catalog this chameleon. You describe all of its colors in detail. Then
  it moves into a different setting and it changes color! Are you metadata still correct?
How can you constantly check whether metadata correspond to an ever evolving
reality?</p>
  </footer>
  </div>

  <div class="slide" id="impact_time-2">
    <figure class="cover width">
        <img src="images/truck.jpg"
             alt="[Crushed fire truck]">
             <figcaption>
               ©2014 <a href="http://www.mirror.co.uk/incoming/gallery/world-trade-center-museum-3547091">
                 Menelik Simpson</a>
             </figcaption>
    </figure>
    <footer>
      <p>The image represents one of the trucks which is now on display in the 9/11
      Museum and Memorial. As a collection holder, the museum had to permanently re-adapt
      the metadata schema it was using in the database to document its collection, as you
      can not describe a truck in the same manner one would create metadata for a photographe
      for example. This illustrates how, based on the evolving nature of its collection,
      a heritage institution has to incorporate changes and update its metadata schema.
      </p>
  </footer>
  </div>

<div class="slide" id="hermeneutics">
    <h2>
      We can make use of hermeneutics as a tool to make sense of quality
    </h2>
    <blockquote class="next">
      <p>Process of understanding moving from parts of a whole
      to a global understanding of the whole and back
      to individual parts in an iterative manner.</p>
      <cite><a href="http://www.jstor.org/stable/249410">Klein et al, 1999</a></cite>
    </blockquote>
    <p><a href="http://www.emeraldinsight.com/doi/abs/10.1108/00220411111109476">Isabelle Boydens</a> reused Fernand Braudel’s <em>stratified time</em> concept as a
    hermeneutical approach to audit the quality of social security databases</p>
  </div>

  <div class="slide" id="boydens">
    <figure class="cover width">
        <img src="images/boydens.jpg"
             alt="[Hermeneutics]">
    </figure>
    <footer>
      <p>Two key publications to understand how we can make use of hermeneutics to evaluate
      the quality of data. In his seminal work <a href="https://en.wikipedia.org/wiki/Fernand_Braudel#La_M.C3.A9diterran.C3.A9e">
      The Mediterranean</a>, Fernand Braudel developed his hermeneutical framework of the
    stratified time to analyse the history of the Mediterranean area at the time of Philips II.
  Isabelle Boydens reused his thinking </p>
    </footer>
  </div>

    <div class="slide" id="emirical">
    <h2>Implications of living in an Empirical World</h2>
  	<p>The work of Boydens demonstrates we can not assert a direct correspondance between the empirical, ever-changing world
  	and the metadata and database schema representing it</p>
  	<p>Defining data quality in a deterministic manner (e.g. MIT Total Data Quality Program)
  	makes no sense for empirical application domains</p>
  </div>

   <div class="slide" id="stratified">
    <h2>Stratified time applied on social security databases by Boydens</h2>
  	<ul>
  	<li>Long term
  	<ul><li>Evolution of policies and legislation</li></ul>
  	</li>
  	<li>Intermediate term
  	<ul><li>Evolution of technologies and standards</li></ul>
  	</li>
  	<li>Short term
  	<ul><li>Evolution of the objects the database documents</li></ul>
  	</li>
  	</ul>
  </div>

  <div class="slide" id="paper">
    <figure class="cover width">
        <img src="images/jod.jpg"
             alt="[Paper Isabelle Boydens and Seth van Hooland]">
    </figure>
    <footer>
      <p>This <a href="http://www.emeraldinsight.com/doi/abs/10.1108/00220411111109476">paper</a>
      by Boydens and van Hooland presents in detail the usage of the hermeneutical framework
      of Braudel to evaluate the quality of databases.
      </p>
  </footer>
  </div>

  <div class="slide" id="theory_practice">
    <h2>From theory to practice…</h2>
  	<ul>
  	<li>Change is a fundamental notion to deal with…</li>
    <li>Boydens underlined that we should not ask “Are the metadata correct?”
      but “How do they evolve through time?”
  		<ul>
  		<li>Incorporate tools which help to monitor change</li>
  		<li>If values do not correspond to the schema, the schema itself may have
  		to be questioned</li>
  		<li>Practice of <em>data-profiling</em> helps to develop data auditing skills</li>
  		</ul>
  	</li>
  	</ul>
  </div>

  <div class="slide" id="profiling">
    <h2>
      Getting to grips with data profiling
    </h2>
    <blockquote class="next">
      <p>The use of analytical techniques to discover the true structure, content
      and quality of a collection of data.</p>
      <cite><a href="http://www.worldcat.org/title/quality-the-accuracy-dimension/oclc/52356695">Olson, 2003</a></cite>
    </blockquote>
    <p>The next module will explain in detail how a tool such as OpenRefine
      can help you to spot data quality issues.</p>
  </div>

  <div class="slide" id="police">
    <figure class="cover width">
        <img src="images/police.jpg"
             alt="[Police]">
             ©2009 <a href="https://en.wikipedia.org/wiki/Victoria_Police">
               Wikipedia</a>
    </figure>
    <footer>
      <p>"There are no metadata police" <a href="http://managemetadata.com/">Diane Hillman</a> once famously said,
      but data profiling will allow you to become an investigator who can effeciently perform a data quality audit.</p>
    </footer>
  </div>

    <div class="slide" id="quality-audit">
    <h2>Recipe for a data quality audit </h2>
  	<ul>
  	<li>We will focus on the following ingredients:
  		<ul>
  		<li>Flattening data</li>
  		<li>Column names</li>
  		<li>Empty columns</li>
  		<li>Data types</li>
  		<li>Length of entries</li>
  		<li>Empty fields</li>
  		<li>Field overloading</li>
  		</ul>
  	</li>
  	</ul>
  </div>

   <div class="slide" id="flattening">
    <h2>Flattening data</h2>
  	<ul>
  	<li>Data profiling and cleaning techniques are applied outside the information system itself</li>
  	<li>These applications mostly ingest <em>flat files</em> so an export process from your
      information system to CSV or TSV files will be needed</li>
  	</ul>
  </div>

     <div class="slide" id="columns">
    <h2>Columns as a starting point</h2>
  	<ul>
  	<li>Simple SQL command to create a column of a table:
  		<ul><li><code>ALTER TABLE artwork ADD title VARCHAR;</code></li></ul>
  	</li>
  	<li>It is surprising how much can go wrong with
  		<ul>
  		<li>Name of the column</li>
  		<li>Data type</li>
  		<li>Length</li>
  		</ul>
  	</li>
  	</ul>
  </div>

  <div class="slide" id="names">
    <h2>Interpretation of the title of a field</h2>
  	<ul>
  	<li>Seems simple to interpret in the context of our art catalogue but
  	this is not always the case</li>
  	<li>Generic, ambiguous or polysemic names can create a lot of confusion:
  		<ul>
        <li>What to expect from a field entitled <code>Sold</code>?
          A binary yes/no, the name of the seller, the amount?</li>
  		</ul>
  	<li>Often unused columns are reused without renaming them</li>
  	</ul>
  </div>

    <div class="slide" id="empty">
    <h2>Issues with empty columns</h2>
  	<ul>
  	<li>Appear everywhere, due to  a variety of reasons:
      <ul><li>Pre-configured settings
 	of databases resulting in a series of irrelevant columns which are never used</li>
 	<li>Data can loose their relevance and be deleted at some point, but the columns
    as such are rarely
 	removed from the system</li>
      </ul>
  <li>Fear of losing data prevents people from removing them, but
    results in systems with lots of unused columns</li>
 	</ul>
  	</div>

    <div class="slide" id="data_types">
    <h2>Data types</h2>
  	<ul>
  	<li>In our SQL example, <code>VARCHAR</code> was mentioned as a data type</li>
 	<li>Other common data types include Text, Number, Boolean or Date</li>
 	<li>All data types can be easily encoded with Text, makes you loose less time but things
 	can get very messy over time</li>
 	</ul>
  	</div>

    <div class="slide" id="dates">
      <h2>Biggest metadata horror: dates!</h2>
    	<p>There is an incredible range of possibilities to express dates. Here
      are just a few examples:</p>
    	<table>
    	<tr>
      	<th>Pattern</th>
      	<th>Example</th>
     	</tr>
    	<tr>
      <td>empty</td>
      <td></td>
      </tr>
    	<tr>
      <td>9999-9999</td>
      <td>1891-1912</td>
    	</tr>
  	<tr>
      <td>9999</td>
      <td>1912</td>
    	</tr>
    	<tr>
      <td>99-99/9999</td>
      <td>09-10/1912</td>
    	</tr>
    	<tr>
      <td>99/9999</td>
      <td>01-1912</td>
    	</tr>
    	<tr>
      <td>99/99/99</td>
      <td>04/08/12</td>
    	</tr>
    	<tr>
      <td>AAA 9999</td>
      <td>May 1912</td>
    	</tr>
  	</table>
    	</div>


  	<div class="slide" id="length">
    <h2>Length of entries</h2>
  	<ul>
  	<li>Seems to have lost its pertinence with decreasing storage costs</li>
 	<li>Text length of entries can be a very interesting parameter to analyse
    <ul><li>If you expect the name of an individual in a field and the average
      text length is 250 characters, there might be an issue…</li>
      <li>Especially the outlier values, being the very short or long ones, can
     be a good place to start your analysis</li>
    </ul>
  </li>

 	</ul>
  	</div>

  	<div class="slide" id="empty-fields">
    <h2>Empty fields</h2>
  	<p>Variety of options to express that a field is empty:
  	no value, encoding <em>null</em>, <em>no value</em> etc</p>
  	<p>Diversity of reasons: value is not (yet) known, not applicable, lack of resources</p>
  	<p>Rarely possible to document this</p>
  	<p>Specific case: trailing white spaces</p>
  	</div>

    <div class="slide" id="malevich">
      <figure class="cover width">
          <img src="images/malevich.jpg"
               alt="[Malevich painting]">
               <figcaption>
                 ©2014 <a href="http://www.independent.co.uk/arts-entertainment/art/features/kasimir-malevichs-black-square-what-does-it-say-to-you-9608316.html">
                   Micha Theiner</a>
               </figcaption>
      </figure>
      <footer>
        <p>The iconic <cite>Black Square</cite> by Kazimir Malevich, of which he did a first
          version in 1905, is a good illustration of the complexity behind the representation
          and interpretation of the actual absence of something. Malevich himself said about
          the painting that
          <q>it is from zero, in zero, that the true movement of being begins</q>.
          Across application domains, it has been demonstrated
          how difficult it is to document the absence of a value.
        </p>
    </footer>
    </div>

  	<div class="slide" id="overloading">
    <h2>Field overloading</h2>
  	<p>Encoding in one field of values which should be split out over multiple fields,
      due to:
  	<ul>
  	<li>repeating values</li>
 	<li>different realities addressed by a generic field</li>
 	</ul>
 	<p>Impacts search and retrieval but also limits data analysis and cleaning</p>
  	</div>

  <div class="evaluation slide" id="eval1">
    <h2>Self-assessment 1</h2>
    <p>Why is data quality so relevant in a Linked Data context?</p>
    <ol>
      <li>
        The closed-world assumption of the Linked Data paradigm limits the amount of data available.
        <ul><li>No, Linked Data is based on the open world assumption, implying that no one at a certain moment knows exactly what type of data are available and the type of constraints they respect.</li></ul>
      </li>
      <li class="correct">
        Linked Data holds the potential danger of introducing erroneous and conflicting data.
        <ul><li>Yes, without specific efforts to clean original data sources and ensuring standardised methods and tools to evaluate and compare data set published as Linked Data, the issue of data quality might seriously undermine the potential of Linked Data for libraries.</li></ul>
      </li>
      <li class="half correct">
        The introduction of Linked Data will boost the quality of library catalogs.
        <ul><li>It depends! Using data from very diverse and heterogeneous sources might seriously undermine the quality of catalogs.</li></ul>
      </li>
    </ol>
  </div>

  <div class="evaluation slide" id="eval2">
    <h2>Self-assessment 2</h2>
    <p>Why is it important to distinguish deterministic from empirical data when talking about metadata quality?</p>
    <ol>
      <li class="correct">
        Contrary to deterministic data, there exist no formal theories to validate empirical data
        <ul><li>Yes! For deterministic data there are fixed theories which no longer evolve, such as is the case with algebra. 1 + 1 will always equal 2.</li></ul>
      </li>
      <li>
        There are more issues with deterministic data.
        <ul><li>No, irrelevant answer.</li></ul>
      </li>
      <li>
        Because empirical data can not be cleaned.
        <ul><li>No, it is not because we can not establish a direct correspondence between the observable and the data that one can not identify errors and rectify them.</li></ul>
      </li>
    </ol>
  </div>


  <div class="evaluation slide" id="eval3">
    <h2>Self-assessment 3</h2>
    <p>What is field overloading and why is it problematic?</p>
    <ol>
      <li>
        The issue rises when you go beyond the number of characters which may be encoded in a field.
        <ul><li>No! The length of an entry can definitively be an interesting data quality indicator, but field overloading is not linked to the length of an entry.</li></ul>
      </li>
      <li>
        This issue mainly rises when you transfer data from a flat file to a database.
        <ul><li>No, it tends to be the other way around. Moving from a well-structured database, with clear definitions of fields, to a flat file might result in packing together related but different (e.g. surname and family name) fields.</li></ul>
      </li>
      <li class="correct">
        Field overloading occurs when related data are put together in the same field.
        <ul><li>Yes, this lowers the possibilities to clearly define encoding constraints and structured search.</li></ul>
      </li>
    </ol>

      </div>

  <div class="evaluation slide" id="eval4">
    <h2>Self-assessment 4</h2>
    <p>Why is it important to think about how we communicate about absent values?</p>
    <ol>
      <li>
        In order to save space.
        <ul><li>No, this is not a relevant answer.</li></ul>
      </li>
      <li>
        In order to avoid them at all times.
        <ul><li>No! Both for conceptual and operational reasons, it is impossible to avoid empty fields. The important aspect is to document the reason behind the absence of a value.</li></ul>
      </li>
      <li class="correct">
        An empty field can be there for a large variety of reasons. Knowing the reason can be important in order to know how to interpret the absence.
        <ul><li>Yes! A value might not be known or not applicable, or there simply might not be enough resources to fill it in.</li></ul>
      </li>
    </ol>
  </div>

  <div class="progress"></div>
  <footer>
    <p class="badge"><a href="https://github.com/shower/shower">Fork me on GitHub</a></p>
    <p class="logos">
      <a href="https://www.imls.gov/"><img alt="Institute of Museum and Library Services" src="../images/imls.svg"></a>
      <a href="http://drexel.edu/cci/"><img alt="Drexel University College of Computing &amp; Informatics" src="../images/drexel.png"></a>
    </p>
    <p class="license">
      <a rel="license" href="https://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" src="../images/cc-by.svg" /></a>
      Except where otherwise noted, the content of these slides is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
    </p>
    <p>
      <a id="twitter" target="_blank" href="https://twitter.com/intent/tweet?hashtags=LD4Lib&amp;via=freemetadata&amp;related=freemetadata,sethvanhooland,RubenVerborgh&amp;url=http%3A%2F%2Fcourse.freeyourmetadata.org%2F" title="Tweet about this">Tweet about this</a>
    </p>
  </footer>
	<script src="../scripts/shower.min.js"></script>
	<script src="../scripts/enhancements.js"></script>
</body>
</html>
